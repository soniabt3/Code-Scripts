{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b3ba20",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c964ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ydata-profiling --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acdaa7",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27dfb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\st7725\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dataset Profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "#Sklearn libraries and modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "\n",
    "#Object Initialization\n",
    "sc = StandardScaler()\n",
    "label_encoder = preprocessing.LabelEncoder() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1491bc1",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0d550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('train.csv')\n",
    "test_dataset = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb683f8b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df003470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(train_df)\n",
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0207d04",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5403cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CReating Version Copies\n",
    "train_df = train_dataset\n",
    "test_df = test_dataset\n",
    "\n",
    "#Dropping the rows with null values\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "#Dropping Columns\n",
    "train_df = train_df.drop(['PassengerId', 'Cabin','Name'], axis=1)\n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "train_df['HomePlanet']= label_encoder.fit_transform(train_df['HomePlanet'])  \n",
    "train_df['CryoSleep']= label_encoder.fit_transform(train_df['CryoSleep'])  \n",
    "train_df['Destination']= label_encoder.fit_transform(train_df['Destination'])  \n",
    "train_df['VIP']= label_encoder.fit_transform(train_df['VIP'])  \n",
    "train_df['Transported']= label_encoder.fit_transform(train_df['Transported'])  \n",
    "\n",
    "X = train_df.iloc[:, :-1].values\n",
    "y = train_df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fd1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[636 195]\n",
      " [168 653]]\n",
      "Accuracy:  0.7802663438256658\n",
      "\n",
      "\n",
      "K-Nearest Neighbors\n",
      "[[629 202]\n",
      " [182 639]]\n",
      "Accuracy:  0.7675544794188862\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines\n",
      "[[643 188]\n",
      " [178 643]]\n",
      "Accuracy:  0.7784503631961259\n",
      "\n",
      "\n",
      "Kernel SVM\n",
      "[[641 190]\n",
      " [169 652]]\n",
      "Accuracy:  0.7826876513317191\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "[[386 445]\n",
      " [ 71 750]]\n",
      "Accuracy:  0.6876513317191283\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "[[582 249]\n",
      " [179 642]]\n",
      "Accuracy:  0.7409200968523002\n",
      "\n",
      "\n",
      "Random Decision Tree\n",
      "[[652 179]\n",
      " [188 633]]\n",
      "Accuracy:  0.7778450363196125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicted Values against test\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Accuracy and confusion matrix\n",
    "print(\"Logistic Regression\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#K-Nearest Neighbors\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"K-Nearest Neighbors\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Support Vector Machines\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Support Vector Machines\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Kernel SVM\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Kernel SVM\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Naive Bayes\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Decision Tree\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Decision Tree\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Random Decision Tree\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Random Decision Tree\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6381f63e",
   "metadata": {},
   "source": [
    "# On The Actual Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888b5274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dropping Columns\n",
    "# test_df = test_df.drop(['PassengerId', 'Cabin','Name'], axis=1)\n",
    "  \n",
    "# # Encode labels in column 'species'. \n",
    "# test_df['HomePlanet']= label_encoder.fit_transform(test_df['HomePlanet'])  \n",
    "# test_df['CryoSleep']= label_encoder.fit_transform(test_df['CryoSleep'])  \n",
    "# test_df['Destination']= label_encoder.fit_transform(test_df['Destination'])  \n",
    "# test_df['VIP']= label_encoder.fit_transform(test_df['VIP'])  \n",
    "\n",
    "# X_train = train_df.iloc[:, :-1].values\n",
    "# y_train = train_df.iloc[:, -1].values\n",
    "\n",
    "# X_test = test_df.iloc[:, :].values\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf80074",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10b84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING THE CRYOSLEEP DECISION TREE MODEL TO FILL IN MISSING VALUES \n",
    "# #CReating Version Copies\n",
    "# train_df = train_dataset\n",
    "# test_df = test_dataset\n",
    "\n",
    "# #Dropping the rows with null values\n",
    "# train_df = train_df.dropna()\n",
    "\n",
    "# train_df['CryoSleep']= label_encoder.fit_transform(train_df['CryoSleep'])  \n",
    "\n",
    "# #RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "# train_df = train_df[['CryoSleep','RoomService',\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]]\n",
    "\n",
    "# X = train_df.iloc[:, 2:].values\n",
    "# y = train_df.iloc[:, 0:1].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# #Decision Tree\n",
    "# classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# print(\"Decision Tree\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "# print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c6855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING THE HomePlanet MODEL TO FILL IN MISSING VALUES \n",
    "\n",
    "# #RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "# train_df = train_df[['HomePlanet',0,1]]\n",
    "\n",
    "# X = train_df.iloc[:, 1:3].values\n",
    "# y = train_df.iloc[:, 0:1].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# #Decision Tree\n",
    "# classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# print(\"Decision Tree\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "# print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f1df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation of column A against all others\n",
    "# method{‘pearson’, ‘kendall’, ‘spearman’} \n",
    "# train_df.corr(method='kendall')['HomePlanet']\n",
    "\n",
    "# # Encode labels in column 'species'. \n",
    "# train_df['Destination']= label_encoder.fit_transform(train_df['Destination'])  \n",
    "# train_df['VIP']= label_encoder.fit_transform(train_df['VIP'])  \n",
    "# train_df['Transported']= label_encoder.fit_transform(train_df['Transported'])  \n",
    "# train_df['Cabin_1']= label_encoder.fit_transform(train_df['Cabin_1'])  \n",
    "# train_df['Cabin_3']= label_encoder.fit_transform(train_df['Cabin_3'])  \n",
    "\n",
    "# train_df = train_df.astype({'family':int, 'family_count':int,'HomePlanet': int, 'CryoSleep': int, 'Destination': int, 'VIP': int, 'Transported': int, 'Cabin_1': int, 'Cabin_3': int})\n",
    "\n",
    "# profile = ProfileReport(train_df)\n",
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fca7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 0, True: 1, nan: 2}\n",
      "{'Earth': 0, 'Europa': 1, 'Mars': 2, nan: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cryosleep_model['CryoSleep']= label_encoder.fit_transform(cryosleep_model['CryoSleep'])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cs_test['CryoSleep'] = y_pred\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homeplanet_model['HomePlanet']= label_encoder.fit_transform(homeplanet_model['HomePlanet'])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homeplanet_model[0]= label_encoder.fit_transform(homeplanet_model[0])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hp_test_2[\"HomePlanet\"] = 0\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:126: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"VIP\"].fillna(False, inplace = True)\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3509536503.py:126: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df[\"VIP\"].fillna(False, inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 0, True: 1}\n",
      "Logistic Regression\n",
      "[[827 189]\n",
      " [398 622]]\n",
      "Accuracy:  0.7116895874263262\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "[[761 255]\n",
      " [426 594]]\n",
      "Accuracy:  0.6655206286836935\n",
      "\n",
      "\n",
      "Support Vector Machines\n",
      "[[857 159]\n",
      " [417 603]]\n",
      "Accuracy:  0.7170923379174853\n",
      "\n",
      "\n",
      "Kernel SVM\n",
      "[[857 159]\n",
      " [417 603]]\n",
      "Accuracy:  0.7170923379174853\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "[[749 267]\n",
      " [358 662]]\n",
      "Accuracy:  0.6930255402750491\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "[[828 188]\n",
      " [382 638]]\n",
      "Accuracy:  0.7200392927308448\n",
      "\n",
      "\n",
      "Random Decision Tree\n",
      "[[786 230]\n",
      " [361 659]]\n",
      "Accuracy:  0.7097249508840865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CReating Version Copies\n",
    "train_df = train_dataset\n",
    "\n",
    "# Handling RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "train_df['Total_Spent']= train_df[['RoomService',\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "\n",
    "#Dropping these columns\n",
    "train_df = train_df.drop(['RoomService',\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"], axis=1)\n",
    "\n",
    "#Handling Cabin\n",
    "#Splitting the column 'Cabin'\n",
    "x = train_df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "#Adding these new columns back to the original dataset\n",
    "train_df = pd.concat([train_df.reset_index(drop=True),x.reset_index(drop=True)], axis=1)\n",
    "#Dropping Cabin\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "\n",
    "#Handling CryoSleep\n",
    "cryosleep_model = train_df[['PassengerId','CryoSleep','Total_Spent']]\n",
    "\n",
    "#Showcasing the encoded labels for cryosleep\n",
    "label_encoder.fit(cryosleep_model['CryoSleep'])\n",
    "cryosleep_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(cryosleep_mapping)\n",
    "\n",
    "#Changing the dataset \n",
    "cryosleep_model['CryoSleep']= label_encoder.fit_transform(cryosleep_model['CryoSleep']) \n",
    "\n",
    "#CryoSleep test set\n",
    "cs_test = cryosleep_model.loc[cryosleep_model['CryoSleep'] == 2]\n",
    "\n",
    "#Cryosleep train set\n",
    "cs_train = cryosleep_model.loc[cryosleep_model['CryoSleep'] != 2]\n",
    "\n",
    "#Creating the predictor variables \n",
    "X_train = cs_train.iloc[:,2:].values\n",
    "y_train = cs_train.iloc[:, 1:2].values\n",
    "\n",
    "#Creating the predicted variables \n",
    "X_test = cs_test.iloc[:,2:].values\n",
    "\n",
    "#Scaling dimnesions \n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Training the decision tree\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Adding predictions back to the original \n",
    "cs_test['CryoSleep'] = y_pred\n",
    "\n",
    "#Combining both results \n",
    "cryosleep_model = pd.concat([cs_train, cs_test], ignore_index=True) \n",
    "\n",
    "#Dropping the old column\n",
    "train_df = train_df.drop('CryoSleep',axis=1)\n",
    "\n",
    "#Getting the new cryosleep column\n",
    "train_df = train_df.merge(cryosleep_model[['PassengerId','CryoSleep']], on='PassengerId', how='left')\n",
    "\n",
    "#Handling HomePlanet\n",
    "homeplanet_model = train_df[['PassengerId','HomePlanet',0,1]]\n",
    "\n",
    "#Showcasing the encoded labels for homeplanet\n",
    "label_encoder.fit(homeplanet_model['HomePlanet'])\n",
    "homeplanet_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(homeplanet_mapping)\n",
    "\n",
    "#Changing the dataset \n",
    "homeplanet_model['HomePlanet']= label_encoder.fit_transform(homeplanet_model['HomePlanet']) \n",
    "homeplanet_model[0]= label_encoder.fit_transform(homeplanet_model[0]) \n",
    "\n",
    "#HomePlanet test set\n",
    "hp_test = homeplanet_model.loc[homeplanet_model['HomePlanet'] == 3]\n",
    "\n",
    "#HomePlanet train set\n",
    "hp_train = homeplanet_model.loc[homeplanet_model['HomePlanet'] != 3]\n",
    "\n",
    "#Special case \n",
    "hp_test_2 = hp_test.loc[homeplanet_model[1].isnull()]\n",
    "hp_test_2[\"HomePlanet\"] = 0\n",
    "#train_df['HomePlanet'].mode()[0]\n",
    "\n",
    "hp_train_2 = hp_train.loc[homeplanet_model[1].isnull()]\n",
    "\n",
    "#Fixing the Training anf Testing sets\n",
    "hp_test = hp_test.loc[homeplanet_model[1].notnull()]\n",
    "hp_train = hp_train.loc[homeplanet_model[1].notnull()]\n",
    "\n",
    "#Creating the predictor variables \n",
    "X_train = hp_train.iloc[:,2:].values\n",
    "y_train = hp_train.iloc[:, 1:2].values\n",
    "\n",
    "\n",
    "#Creating the predicted variables \n",
    "X_test = hp_test.iloc[:,2:].values\n",
    "\n",
    "#Scaling dimnesions \n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Training the decision tree\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Adding predictions back to the original \n",
    "hp_test['HomePlanet'] = y_pred\n",
    "\n",
    "#Combining both results \n",
    "homeplanet_model = pd.concat([hp_train, hp_test, hp_train_2, hp_test_2], ignore_index=True) \n",
    "\n",
    "#Dropping the old column\n",
    "train_df = train_df.drop('HomePlanet',axis=1)\n",
    "\n",
    "#Getting the new cryosleep column\n",
    "train_df = train_df.merge(homeplanet_model[['PassengerId','HomePlanet']], on='PassengerId', how='left')\n",
    "\n",
    "#Handling PassengerId\n",
    "#'PassengerId',\n",
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "\n",
    "#Handling VIP\n",
    "train_df[\"VIP\"].fillna(False, inplace = True)\n",
    "\n",
    "#Dropping the rows with null values\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "#Dropping Any Duplicates\n",
    "train_df = train_df.drop_duplicates()\n",
    "\n",
    "#Renaming columns \n",
    "train_df.rename(columns = {0:'Cabin_1',1:'Cabin_2',2:'Cabin_3'}, inplace = True) \n",
    "\n",
    "#Handling PassengerId\n",
    "#Splitting the column 'PassengerId'\n",
    "x = train_df[\"PassengerId\"].str.split(\"_\", expand=True)\n",
    "#Adding these new columns back to the original dataset\n",
    "train_df = pd.concat([train_df.reset_index(drop=True),x.reset_index(drop=True)], axis=1)\n",
    "#Dropping Cabin\n",
    "train_df = train_df.drop(['PassengerId'], axis=1)\n",
    "#Renaming columns \n",
    "train_df.rename(columns = {0:'Group_Id',1:'PID'}, inplace = True) \n",
    "train_df = train_df.astype({'PID': int})\n",
    "train_df['family'] = train_df.groupby('Group_Id')['PID'].transform(lambda x: 1 if x.nunique() > 1 else 0)\n",
    "train_df['family_count'] = train_df.groupby('Group_Id')['PID'].transform(lambda x: x.nunique())\n",
    "train_df = train_df.drop(['Group_Id','PID'],axis=1)\n",
    "\n",
    "#Moving Columns\n",
    "train_df = train_df.reindex(sorted(train_df.columns), axis=1)\n",
    "train_df = train_df[[c for c in train_df if c not in ['Transported']] + ['Transported']]\n",
    "\n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "train_df['Destination']= label_encoder.fit_transform(train_df['Destination'])  \n",
    "train_df['VIP']= label_encoder.fit_transform(train_df['VIP'])  \n",
    "\n",
    "label_encoder.fit(train_df['Transported'])\n",
    "tp = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(tp)\n",
    "train_df['Transported']= label_encoder.fit_transform(train_df['Transported'])\n",
    "# train_df = train_df.replace({True: 1, False: 0})\n",
    "\n",
    "train_df['Cabin_1']= label_encoder.fit_transform(train_df['Cabin_1'])  \n",
    "train_df['Cabin_3']= label_encoder.fit_transform(train_df['Cabin_3'])  \n",
    "\n",
    "train_df = train_df.drop(['Age','VIP','Total_Spent','Cabin_2','Cabin_3','family_count'], axis=1)\n",
    "#remove family_count, Cabin_3, Total_Spent, VIP, Age\n",
    "# keep family, HomePlanet, CryoSleep, Cabin_2, Cabin_1, Destination\n",
    "\n",
    "X = train_df.iloc[:, :-1].values\n",
    "y = train_df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Logistic Regression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicted Values against test\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Accuracy and confusion matrix\n",
    "print(\"Logistic Regression\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#K-Nearest Neighbors\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"K-Nearest Neighbors\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Support Vector Machines\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Support Vector Machines\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Kernel SVM\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Kernel SVM\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Naive Bayes\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Decision Tree\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Decision Tree\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "#Random Decision Tree\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Random Decision Tree\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff537a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3909631341.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homeplanet_model['HomePlanet']= label_encoder.fit_transform(homeplanet_model['HomePlanet'])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3909631341.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homeplanet_model[0]= label_encoder.fit_transform(homeplanet_model[0])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3909631341.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hp_test_2[\"HomePlanet\"] = 0\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3909631341.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cryosleep_model['CryoSleep']= label_encoder.fit_transform(cryosleep_model['CryoSleep'])\n",
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\3909631341.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cs_test['CryoSleep'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "test_df = test_dataset\n",
    "\n",
    "#Handling Cabin\n",
    "x = test_df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True),x.reset_index(drop=True)], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)\n",
    "\n",
    "#Handling HomePlanet\n",
    "homeplanet_model = test_df[['PassengerId','HomePlanet',0,1]]\n",
    "label_encoder.fit(homeplanet_model['HomePlanet'])\n",
    "homeplanet_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "homeplanet_model['HomePlanet']= label_encoder.fit_transform(homeplanet_model['HomePlanet']) \n",
    "homeplanet_model[0]= label_encoder.fit_transform(homeplanet_model[0]) \n",
    "hp_test = homeplanet_model.loc[homeplanet_model['HomePlanet'] == 3]\n",
    "hp_train = homeplanet_model.loc[homeplanet_model['HomePlanet'] != 3]\n",
    "hp_test_2 = hp_test.loc[homeplanet_model[1].isnull()]\n",
    "hp_test_2[\"HomePlanet\"] = 0\n",
    "hp_train_2 = hp_train.loc[homeplanet_model[1].isnull()]\n",
    "hp_test = hp_test.loc[homeplanet_model[1].notnull()]\n",
    "hp_train = hp_train.loc[homeplanet_model[1].notnull()]\n",
    "X_train = hp_train.iloc[:,2:].values\n",
    "y_train = hp_train.iloc[:, 1:2].values\n",
    "X_test = hp_test.iloc[:,2:].values\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "hp_test['HomePlanet'] = y_pred\n",
    "homeplanet_model = pd.concat([hp_train, hp_test, hp_train_2, hp_test_2], ignore_index=True) \n",
    "test_df = test_df.drop('HomePlanet',axis=1)\n",
    "test_df = test_df.merge(homeplanet_model[['PassengerId','HomePlanet']], on='PassengerId', how='left')\n",
    "\n",
    "#Renaming columns \n",
    "test_df.rename(columns = {0:'Cabin_1',1:'Cabin_2',2:'Cabin_3'}, inplace = True) \n",
    "\n",
    "# Handling RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "test_df['Total_Spent']= test_df[['RoomService',\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "test_df = test_df.drop(['RoomService',\"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"], axis=1)\n",
    "\n",
    "#Handling CryoSleep\n",
    "cryosleep_model = test_df[['PassengerId','CryoSleep','Total_Spent']]\n",
    "label_encoder.fit(cryosleep_model['CryoSleep'])\n",
    "cryosleep_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "cryosleep_model['CryoSleep']= label_encoder.fit_transform(cryosleep_model['CryoSleep']) \n",
    "cs_test = cryosleep_model.loc[cryosleep_model['CryoSleep'] == 2]\n",
    "cs_train = cryosleep_model.loc[cryosleep_model['CryoSleep'] != 2]\n",
    "X_train = cs_train.iloc[:,2:].values\n",
    "y_train = cs_train.iloc[:, 1:2].values\n",
    "X_test = cs_test.iloc[:,2:].values\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cs_test['CryoSleep'] = y_pred\n",
    "cryosleep_model = pd.concat([cs_train, cs_test], ignore_index=True) \n",
    "test_df = test_df.drop('CryoSleep',axis=1)\n",
    "test_df = test_df.merge(cryosleep_model[['PassengerId','CryoSleep']], on='PassengerId', how='left')\n",
    "\n",
    "#Handling PassengerID\n",
    "x = test_df[\"PassengerId\"].str.split(\"_\", expand=True)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True),x.reset_index(drop=True)], axis=1)\n",
    "test_df = test_df.drop(['PassengerId'], axis=1)\n",
    "test_df.rename(columns = {0:'Group_Id',1:'PID'}, inplace = True) \n",
    "test_df = test_df.astype({'PID': int})\n",
    "test_df['family'] = test_df.groupby('Group_Id')['PID'].transform(lambda x: 1 if x.nunique() > 1 else 0)\n",
    "test_df['family_count'] = test_df.groupby('Group_Id')['PID'].transform(lambda x: x.nunique())\n",
    "test_df = test_df.drop(['Group_Id','PID'],axis=1)\n",
    "\n",
    "#Dropping Name Column\n",
    "test_df = test_df.drop(['Name'],axis=1)\n",
    "\n",
    "#Ordering Columns\n",
    "test_df = test_df.reindex(sorted(test_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd127d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels in column 'species'. \n",
    "test_df['Destination']= label_encoder.fit_transform(test_df['Destination'])  \n",
    "test_df['VIP']= label_encoder.fit_transform(test_df['VIP'])   \n",
    "test_df['Cabin_1']= label_encoder.fit_transform(test_df['Cabin_1'])  \n",
    "test_df['Cabin_3']= label_encoder.fit_transform(test_df['Cabin_3'])  \n",
    "\n",
    "test_df = test_df.drop(['Age','VIP','Total_Spent','Cabin_2','Cabin_3','family_count'], axis=1)\n",
    "\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "y_train = train_df.iloc[:, -1].values\n",
    "\n",
    "X_test = test_df.iloc[:,:].values\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Random Decision Tree\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df2c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st7725\\AppData\\Local\\Temp\\ipykernel_21144\\1448603096.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  submission = submission.replace({1: True, 0: False})\n"
     ]
    }
   ],
   "source": [
    "submission = test_dataset\n",
    "submission['Transported'] = y_pred\n",
    "submission = submission[['PassengerId','Transported']]\n",
    "submission = submission.replace({1: True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d48906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('final_prediction.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d68a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
